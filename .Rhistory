pred <- predict(model, tfidf_matrix)$predictions
# 4. å°†é¢„æµ‹ç»“æœè½¬æ¢ä¸ºæ•´æ•°
pred_class <- as.integer(pred)  # æ³¨æ„è¿™é‡Œä¸å†ç”¨ max.col
cat("Predicted class: ", pred_class, "\n")
# 5. æ˜ å°„æƒ…ç»ªåˆ° emoji
emoji_mapping <- c(
"positive" = "ğŸ˜Š",   # 1
"angry" = "ğŸ˜¡",      # 2
"sad" = "ğŸ˜¢",        # 3
"fear" = "ğŸ˜¨",       # 4
"neutral" = "ğŸ˜"     # 5
)
# å°†é¢„æµ‹çš„ç±»åˆ«è½¬æ¢ä¸ºæƒ…ç»ªæ ‡ç­¾
emotion_labels <- c("positive", "angry", "sad", "fear", "neutral")
predicted_emotion <- emotion_labels[pred_class]
# è·å–å¯¹åº”çš„ emoji
predicted_emoji <- emoji_mapping[predicted_emotion]
#cat("Predicted emotion: ", predicted_emotion, "\n")
#return(list(
#emotion = predicted_emotion,
#emoji = predicted_emoji
#))
return(emotion = predicted_emotion)
}
# ç¤ºä¾‹ï¼šåŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹å’Œ TF-IDF æ¨¡å‹ï¼Œè¿›è¡Œé¢„æµ‹
trained_model <- readRDS("trained_rf_ranger_model.rds")
tfidf_model <- readRDS("trained_tfidf_model.rds")
vectorizer <- readRDS("trained_vectorizer.rds")
# ç”¨æˆ·è¾“å…¥
user_input <- "."
result <- predict_emotion_with_emoji(user_input, trained_model, tfidf_model, vectorizer)
#cat("Predicted emotion: ", result$emotion, "\n")
#cat("Predicted emoji: ", result$emoji, "\n")
usethis::use_testthat()
user_input <- "."
result <- predict_emotion_with_emoji(user_input, trained_model, tfidf_model, vectorizer)
#cat("Predicted emotion: ", result$emotion, "\n")
#cat("Predicted emoji: ", result$emoji, "\n")
predict_emotion_with_emoji <- function(text, output_type = "textemoji") {
# 1. åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹å’Œ TF-IDF æ¨¡å‹
trained_model <- readRDS("trained_rf_ranger_model.rds")
tfidf_model <- readRDS("trained_tfidf_model.rds")
vectorizer <- readRDS("trained_vectorizer.rds")
# 2. æ–‡æœ¬é¢„å¤„ç† â†’ è°ƒç”¨ data_preprocessing å‡½æ•°
preprocessed_text <- preprocess_text(text)
if (!is.character(preprocessed_text)) {
stop("Preprocessing failed, the output is not a character string.")
}
# 3. ä½¿ç”¨ TF-IDF æ¨¡å‹åˆ›å»ºç‰¹å¾çŸ©é˜µ
it <- text2vec::itoken(preprocessed_text, progressbar = FALSE)
dtm <- text2vec::create_dtm(it, vectorizer)
tfidf_matrix <- tfidf_model$transform(dtm)
# 4. ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæƒ…ç»ªé¢„æµ‹
pred <- predict(trained_model, tfidf_matrix)$predictions
# 5. å°†é¢„æµ‹ç»“æœè½¬æ¢ä¸ºæ•´æ•°
pred_class <- as.integer(pred)
# 6. æ˜ å°„æƒ…ç»ªåˆ° emoji
emoji_mapping <- c(
"positive" = "ğŸ˜Š",   # 1
"angry" = "ğŸ˜¡",      # 2
"sad" = "ğŸ˜¢",        # 3
"fear" = "ğŸ˜¨",       # 4
"neutral" = "ğŸ˜"     # 5
)
# å°†é¢„æµ‹çš„ç±»åˆ«è½¬æ¢ä¸ºæƒ…ç»ªæ ‡ç­¾
emotion_labels <- c("positive", "angry", "sad", "fear", "neutral")
predicted_emotion <- emotion_labels[pred_class]
# è·å–å¯¹åº”çš„ emoji
predicted_emoji <- emoji_mapping[predicted_emotion]
# æ ¹æ® output_type è¿”å›ä¸åŒå†…å®¹ï¼Œå¹¶è‡ªåŠ¨æ‰“å°
if (output_type == "emotion") {
cat("emotion:", predicted_emotion, "\n")
return(predicted_emotion)
} else if (output_type == "emoji") {
cat("emoji:", predicted_emoji, "\n")
return(predicted_emoji)
} else if (output_type == "textemoji") {
# è¿”å›å¸¦ emoji çš„æ–‡æœ¬å¹¶æ‰“å°
result_text <- paste0(text, " ", predicted_emoji)
cat(result_text, "\n")
return(result_text)
} else {
stop("Invalid output_type. Please choose 'emotion', 'emoji', or 'textemoji'.")
}
}
# ç¤ºä¾‹ï¼šç”¨æˆ·è¾“å…¥
user_input <- "I was scared to death!"
# åªè¿”å›æƒ…ç»ªæ ‡ç­¾
result_emotion <- predict_emotion_with_emoji(user_input, "emotion")
# åªè¿”å›å¯¹åº”çš„ emoji
result_emoji <- predict_emotion_with_emoji(user_input, "emoji")
# è¿”å›å¸¦æœ‰ emoji çš„å®Œæ•´æ–‡æœ¬ï¼ˆé»˜è®¤å‚æ•°ï¼‰
result_textemoji <- predict_emotion_with_emoji(user_input)  # é»˜è®¤å‚æ•°æ˜¯ "textemoji"
predict_emotion_with_emoji <- function(text, output_type = "textemoji") {
# 1. åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹å’Œ TF-IDF æ¨¡å‹
trained_model <- readRDS("trained_rf_ranger_model.rds")
tfidf_model <- readRDS("trained_tfidf_model.rds")
vectorizer <- readRDS("trained_vectorizer.rds")
# 2. æ–‡æœ¬é¢„å¤„ç† â†’ è°ƒç”¨ data_preprocessing å‡½æ•°
preprocessed_text <- preprocess_text(text)
if (!is.character(preprocessed_text)) {
stop("Preprocessing failed, the output is not a character string.")
}
# 3. ä½¿ç”¨ TF-IDF æ¨¡å‹åˆ›å»ºç‰¹å¾çŸ©é˜µ
it <- text2vec::itoken(preprocessed_text, progressbar = FALSE)
dtm <- text2vec::create_dtm(it, vectorizer)
tfidf_matrix <- tfidf_model$transform(dtm)
# 4. ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæƒ…ç»ªé¢„æµ‹
pred <- predict(trained_model, tfidf_matrix)$predictions
# 5. å°†é¢„æµ‹ç»“æœè½¬æ¢ä¸ºæ•´æ•°
pred_class <- as.integer(pred)
# 6. æ˜ å°„æƒ…ç»ªåˆ° emoji
emoji_mapping <- c(
"positive" = "ğŸ˜Š",   # 1
"angry" = "ğŸ˜¡",      # 2
"sad" = "ğŸ˜¢",        # 3
"fear" = "ğŸ˜¨",       # 4
"neutral" = "ğŸ˜"     # 5
)
# å°†é¢„æµ‹çš„ç±»åˆ«è½¬æ¢ä¸ºæƒ…ç»ªæ ‡ç­¾
emotion_labels <- c("positive", "angry", "sad", "fear", "neutral")
predicted_emotion <- emotion_labels[pred_class]
# è·å–å¯¹åº”çš„ emoji
predicted_emoji <- emoji_mapping[predicted_emotion]
# æ ¹æ® output_type è¿”å›ä¸åŒå†…å®¹ï¼Œå¹¶è‡ªåŠ¨æ‰“å°
if (output_type == "emotion") {
cat("emotion:", predicted_emotion, "\n")
return(predicted_emotion)
} else if (output_type == "emoji") {
cat("emoji:", predicted_emoji, "\n")
return(predicted_emoji)
} else if (output_type == "textemoji") {
# è¿”å›å¸¦ emoji çš„æ–‡æœ¬å¹¶æ‰“å°
result_text <- paste0(text, " ", predicted_emoji)
cat(result_text, "\n")
return(result_text)
} else {
stop("Invalid output_type. Please choose 'emotion', 'emoji', or 'textemoji'.")
}
}
# ç¤ºä¾‹ï¼šç”¨æˆ·è¾“å…¥
user_input <- "I am happy!"
# åªè¿”å›æƒ…ç»ªæ ‡ç­¾
result_emotion <- predict_emotion_with_emoji(user_input, "emotion")
# åªè¿”å›å¯¹åº”çš„ emoji
result_emoji <- predict_emotion_with_emoji(user_input, "emoji")
# è¿”å›å¸¦æœ‰ emoji çš„å®Œæ•´æ–‡æœ¬ï¼ˆé»˜è®¤å‚æ•°ï¼‰
result_textemoji <- predict_emotion_with_emoji(user_input)  # é»˜è®¤å‚æ•°æ˜¯ "textemoji"
#' Preprocess Text with Slang Handling
#'
#' This function performs multi-stage text preprocessing, including lowercasing,
#' HTML cleaning, punctuation normalization, contraction expansion, internet slang replacement,
#' emoticon replacement, and final standardization.
#'
#' @param text A character vector of input texts.
#' @param use_textclean Logical. Whether to use \code{textclean} for internet slang and emoticon replacement. Default is \code{TRUE}.
#' @param custom_slang A named character vector providing user-defined slang mappings. Optional.
#'
#' @return  A character vector of cleaned and normalized text.
#'
#' @details
#' The preprocessing pipeline includes:
#' \itemize{
#'   \item Lowercasing the text.
#'   \item Replacing HTML entities and non-ASCII characters.
#'   \item Expanding common English contractions (e.g., "I'm" -> "I am").
#'   \item Replacing internet slang and emoticons if \code{use_textclean} is \code{TRUE}.
#'   \item Handling additional slang defined by the user.
#'   \item Normalizing repeated punctuations and whitespace.
#' }
#'
#' @examples
#' preprocess_text("I'm feeling lit rn!!!")
#' preprocess_text("I can't believe it... lol :)", use_textclean = TRUE)
#'
#' @importFrom stringr str_to_lower str_replace_all str_squish
#' @importFrom textclean replace_html replace_non_ascii replace_internet_slang replace_emoticon
#' @importFrom magrittr %>%
#' @export
preprocess_text <- function(text,
use_textclean = TRUE,
custom_slang = NULL) {
# é˜¶æ®µ1ï¼šåŸºç¡€æ¸…æ´—
text <- text %>%
stringr::str_to_lower() %>%
# å¤„ç†HTMLå®ä½“ï¼ˆå¦‚&nbsp;ï¼‰
textclean::replace_html() %>%
# æ ‡å‡†åŒ–æ ‡ç‚¹ï¼ˆå…¨è§’è½¬åŠè§’ç­‰ï¼‰
textclean::replace_non_ascii()
# é˜¶æ®µ2ï¼šæ”¶ç¼©è¯å¤„ç†
contractions <- c(
# ä¼˜å…ˆå¤„ç†å¸¦"ll"çš„
"i'll" = "i will",
"he'll" = "he will",
"she'll" = "she will",
"we'll" = "we will",
"you'll" = "you will",
"they'll" = "they will",
# ç„¶åå¤„ç†å…¶ä»–
"i'm" = "i am",
"you're" = "you are",
"he's" = "he is",
"she's" = "she is",
"it's" = "it is",
"we're" = "we are",
"they're" = "they are",
"that's" = "that is",
"there's" = "there is",
"here's" = "here is",
"let's" = "let us",
# æœ€åå¤„ç†å¦å®šå½¢å¼
"can't" = "can not",
"won't" = "will not",
"don't" = "do not",
"doesn't" = "does not",
"didn't" = "did not",
"isn't" = "is not",
"aren't" = "are not",
"wasn't" = "was not",
"weren't" = "were not",
"haven't" = "have not",
"hasn't" = "has not",
"hadn't" = "had not",
"shan't" = "shall not"
)
text <- text %>%
stringr::str_replace_all(contractions)
# é˜¶æ®µ3ï¼šä¿šè¯­å¤„ç†
if (use_textclean) {
text <- text %>%
textclean::replace_internet_slang() %>%  # å¤„ç†2000+å¸¸è§ç½‘ç»œç”¨è¯­
textclean::replace_emoticon()           # è¡¨æƒ…ç¬¦å·è½¬æ–‡å­—
}
all_slang <- c(
"lit" = "extremely amazing",
"af" = "as fuck",
"u" = "you",
"ur" = "your",
"rn" = "right now",
"gg" = "good game",
"gl" = "good luck",
"hf" = "have fun",
"tbh" = "to be honest",
"idc" = "i don't care",
"op" = "overpowered",
"nerf" = "weaken",
"buff" = "strengthen",
"4" = "for",
"2" = "to",
"2nite" = "tonight",
"@" = "at",
"abt" = "about",
"f" = "fuck",
custom_slang
)
for (i in seq_along(all_slang)) {
text <- stringr::str_replace_all(
text,
stringr::regex(
paste0("\\b", names(all_slang)[i], "\\b"),
ignore_case = TRUE
),
all_slang[i]
)
}
# åˆå¹¶è‡ªå®šä¹‰ä¿šè¯­ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
if (!is.null(custom_slang)) {
text <- stringr::str_replace_all(
text,
stringr::regex(
paste0("\\b", names(custom_slang), "\\b",
ignore_case = TRUE
),
custom_slang
)
)
}
# é˜¶æ®µ4ï¼šæœ€ç»ˆæ ‡å‡†åŒ–
text %>%
# å¤„ç†é‡å¤æ ‡ç‚¹ï¼ˆä¿ç•™æƒ…æ„Ÿå¼ºåº¦ï¼‰
stringr::str_replace_all("([!?.]){2,}", " \\1") %>%
# ä¿ç•™ç¬¦å·ä½†ç»Ÿä¸€ç©ºæ ¼
stringr::str_replace_all("([[:punct:]])", " \\1 ") %>%
stringr::str_squish()  # å»é™¤å¤šä½™ç©ºæ ¼
}
#' æ„å»ºTF-IDFæ¨¡å‹ï¼ˆç”¨äºè®­ç»ƒé˜¶æ®µï¼‰
#' @param preprocessed_text ç»è¿‡é¢„å¤„ç†çš„æ–‡æœ¬å‘é‡
#' @param max_features æœ€å¤§ç‰¹å¾æ•°
#' @param min_df æœ€å°æ–‡æ¡£é¢‘ç‡
#' @param max_df æœ€å¤§æ–‡æ¡£é¢‘ç‡æ¯”ä¾‹
#' @return åŒ…å«TF-IDFæ¨¡å‹åŠå…¶ç»„ä»¶çš„åˆ—è¡¨
#' @export
train_tfidf_model <- function(preprocessed_text,
max_features = 10000,
min_df = 2,
max_df = 0.8,
priority_words = c("happy", "excited", "grateful", "hopeful", "loving",
"annoyed", "furious", "frustrated",
"sad", "lonely", "disappointed", "hopeless",
"scared", "anxious", "nervous",
"factual", "objective", "informative")) {
if (!is.character(preprocessed_text)) {
stop("è¾“å…¥å¿…é¡»æ˜¯å­—ç¬¦å‘é‡")
}
# å®šä¹‰è‡ªå®šä¹‰åœç”¨è¯ï¼ˆå«ä¿ç•™æƒ…æ„ŸåŠŸèƒ½è¯ï¼‰
custom_stopwords <- c(
"a", "about", "above", "after", "again", "all", "am",
"an", "and", "any", "are", "aren't", "as", "at", "be", "because",
"been", "before", "being", "below", "between", "both", "but", "by",
"can", "can't", "cannot", "could", "couldn't", "did", "didn't", "do",
"does", "doesn't", "doing", "don't", "down", "during", "each", "few",
"for", "from", "further", "had", "hadn't", "has", "hasn't", "have",
"haven't", "having", "he", "he'd", "he'll", "he's", "her", "here",
"hers", "herself", "him", "himself", "his", "how", "i", "i'd", "i'll",
"i'm", "i've", "if", "in", "into", "is", "isn't", "it", "it's", "its",
"itself", "let's", "me", "more", "most", "mustn't", "my", "myself",
"no", "nor", "not", "of", "off", "on", "once", "only", "or", "other",
"ought", "our", "ours", "ourselves", "out", "over", "own", "same",
"she", "she'd", "she'll", "she's", "should", "shouldn't", "so", "some",
"such", "than", "that", "that's", "the", "their", "theirs", "them",
"themselves", "then", "there", "there's", "these", "they", "they'd",
"they'll", "they're", "they've", "this", "those", "through", "to",
"too", "under", "until", "up", "very", "was", "wasn't", "we", "we'd",
"we'll", "we're", "we've", "were", "weren't", "what", "what's",
"when", "when's", "where", "where's", "which", "while", "who", "who's",
"whom", "why", "why's", "will", "with", "won't", "would", "wouldn't",
"you", "you'd", "you'll", "you're", "you've", "your", "yours",
"yourself", "yourselves", "movie", "product","name", "just","people","get",
"one","know","think", "now", "loud", "s","time", "see", "ve", "much", "got",
"go", "way", "tongue" ,"still", "really", "very","d","make", "man", "e", "going",
"back", "thing" , "us", "also", "t", "someone", "say", "something", "day", "look",
"first", "year", "work","looks", "makes", "years", "take", "made", "said",
"life", "post", "things", "find", "getting"
)
# ä¿ç•™çš„æƒ…æ„ŸåŠŸèƒ½è¯
keep_words <- c("not", "no", "never")
final_stopwords <- setdiff(custom_stopwords, keep_words)
# åˆ†è¯å¹¶ç§»é™¤åœç”¨è¯
tokens <- text2vec::word_tokenizer(tolower(preprocessed_text))
tokens_filtered <- lapply(tokens, function(x) {
x[!x %in% final_stopwords]
})
# åˆ›å»ºitokenè¿­ä»£å™¨
it <- text2vec::itoken(tokens_filtered, progressbar = FALSE)
# åˆ›å»ºå¹¶ä¿®å‰ªè¯æ±‡è¡¨ï¼ˆ1-3 gramï¼‰
vocab <- text2vec::create_vocabulary(it, ngram = c(1L, 3L)) %>%
text2vec::prune_vocabulary(
term_count_min = min_df,
doc_proportion_max = max_df,
vocab_term_max = max_features
)
# åˆ›å»ºå‘é‡å™¨å’ŒTF-IDFæ¨¡å‹
vectorizer <- text2vec::vocab_vectorizer(vocab)
tfidf <- text2vec::TfIdf$new()
# åˆ›å»ºTF-IDFç¨€ç–çŸ©é˜µ
dtm <- text2vec::create_dtm(it, vectorizer)
tfidf_matrix <- tfidf$fit_transform(dtm)
# è¿”å›ç»“æœ
return(list(
tfidf_model = tfidf,
vectorizer = vectorizer,
tfidf_matrix = tfidf_matrix
))
}
# ç¤ºä¾‹æ–‡æœ¬ï¼ˆæ­£é¢ã€è´Ÿé¢ã€ä¸­æ€§ã€ä¿šè¯­ç­‰ï¼‰
sample_texts <- readLines(system.file("extdata", "go_emotions_train_text_processed.csv", package = "text2emotion"), warn = FALSE)
trained <- train_tfidf_model(sample_texts)
library(magrittr)
#' æ„å»ºTF-IDFæ¨¡å‹ï¼ˆç”¨äºè®­ç»ƒé˜¶æ®µï¼‰
#' @param preprocessed_text ç»è¿‡é¢„å¤„ç†çš„æ–‡æœ¬å‘é‡
#' @param max_features æœ€å¤§ç‰¹å¾æ•°
#' @param min_df æœ€å°æ–‡æ¡£é¢‘ç‡
#' @param max_df æœ€å¤§æ–‡æ¡£é¢‘ç‡æ¯”ä¾‹
#' @return åŒ…å«TF-IDFæ¨¡å‹åŠå…¶ç»„ä»¶çš„åˆ—è¡¨
#' @export
train_tfidf_model <- function(preprocessed_text,
max_features = 10000,
min_df = 2,
max_df = 0.8,
priority_words = c("happy", "excited", "grateful", "hopeful", "loving",
"annoyed", "furious", "frustrated",
"sad", "lonely", "disappointed", "hopeless",
"scared", "anxious", "nervous",
"factual", "objective", "informative")) {
if (!is.character(preprocessed_text)) {
stop("è¾“å…¥å¿…é¡»æ˜¯å­—ç¬¦å‘é‡")
}
# å®šä¹‰è‡ªå®šä¹‰åœç”¨è¯ï¼ˆå«ä¿ç•™æƒ…æ„ŸåŠŸèƒ½è¯ï¼‰
custom_stopwords <- c(
"a", "about", "above", "after", "again", "all", "am",
"an", "and", "any", "are", "aren't", "as", "at", "be", "because",
"been", "before", "being", "below", "between", "both", "but", "by",
"can", "can't", "cannot", "could", "couldn't", "did", "didn't", "do",
"does", "doesn't", "doing", "don't", "down", "during", "each", "few",
"for", "from", "further", "had", "hadn't", "has", "hasn't", "have",
"haven't", "having", "he", "he'd", "he'll", "he's", "her", "here",
"hers", "herself", "him", "himself", "his", "how", "i", "i'd", "i'll",
"i'm", "i've", "if", "in", "into", "is", "isn't", "it", "it's", "its",
"itself", "let's", "me", "more", "most", "mustn't", "my", "myself",
"no", "nor", "not", "of", "off", "on", "once", "only", "or", "other",
"ought", "our", "ours", "ourselves", "out", "over", "own", "same",
"she", "she'd", "she'll", "she's", "should", "shouldn't", "so", "some",
"such", "than", "that", "that's", "the", "their", "theirs", "them",
"themselves", "then", "there", "there's", "these", "they", "they'd",
"they'll", "they're", "they've", "this", "those", "through", "to",
"too", "under", "until", "up", "very", "was", "wasn't", "we", "we'd",
"we'll", "we're", "we've", "were", "weren't", "what", "what's",
"when", "when's", "where", "where's", "which", "while", "who", "who's",
"whom", "why", "why's", "will", "with", "won't", "would", "wouldn't",
"you", "you'd", "you'll", "you're", "you've", "your", "yours",
"yourself", "yourselves", "movie", "product","name", "just","people","get",
"one","know","think", "now", "loud", "s","time", "see", "ve", "much", "got",
"go", "way", "tongue" ,"still", "really", "very","d","make", "man", "e", "going",
"back", "thing" , "us", "also", "t", "someone", "say", "something", "day", "look",
"first", "year", "work","looks", "makes", "years", "take", "made", "said",
"life", "post", "things", "find", "getting"
)
# ä¿ç•™çš„æƒ…æ„ŸåŠŸèƒ½è¯
keep_words <- c("not", "no", "never")
final_stopwords <- setdiff(custom_stopwords, keep_words)
# åˆ†è¯å¹¶ç§»é™¤åœç”¨è¯
tokens <- text2vec::word_tokenizer(tolower(preprocessed_text))
tokens_filtered <- lapply(tokens, function(x) {
x[!x %in% final_stopwords]
})
# åˆ›å»ºitokenè¿­ä»£å™¨
it <- text2vec::itoken(tokens_filtered, progressbar = FALSE)
# åˆ›å»ºå¹¶ä¿®å‰ªè¯æ±‡è¡¨ï¼ˆ1-3 gramï¼‰
vocab <- text2vec::create_vocabulary(it, ngram = c(1L, 3L)) %>%
text2vec::prune_vocabulary(
term_count_min = min_df,
doc_proportion_max = max_df,
vocab_term_max = max_features
)
# åˆ›å»ºå‘é‡å™¨å’ŒTF-IDFæ¨¡å‹
vectorizer <- text2vec::vocab_vectorizer(vocab)
tfidf <- text2vec::TfIdf$new()
# åˆ›å»ºTF-IDFç¨€ç–çŸ©é˜µ
dtm <- text2vec::create_dtm(it, vectorizer)
tfidf_matrix <- tfidf$fit_transform(dtm)
# è¿”å›ç»“æœ
return(list(
tfidf_model = tfidf,
vectorizer = vectorizer,
tfidf_matrix = tfidf_matrix
))
}
# ç¤ºä¾‹æ–‡æœ¬ï¼ˆæ­£é¢ã€è´Ÿé¢ã€ä¸­æ€§ã€ä¿šè¯­ç­‰ï¼‰
sample_texts <- readLines(system.file("extdata", "go_emotions_train_text_processed.csv", package = "text2emotion"), warn = FALSE)
trained <- train_tfidf_model(sample_texts)
devtools::test()
rm(list = c("preprocess_text", "train_tfidf_model"))
devtools::test()
devtools::test()
devtools::test()
devtools::document()
install.packages(c("caret", "Matrix"))
devtools::document()
devtools::load_all()
install.packages("prodlim")
> devtools::load_all()
devtools::load_all()
devtools::document()
devtools::test()
devtools::test()
devtools::test()
devtools::test()
devtools::test()
usethis::use_vignette("text2emotion")
devtools::test()
devtools::test()
devtools::test()
devtools::test()
devtools::test()
devtools::test()
devtools::check()
install.packages("sass")
devtools::document()
devtools::check()
pkgbuild::has_build_tools(debug = TRUE)
devtools::check()
devtools::check()
devtools::document()
usethis::use_mit_license("Yusong Zhao,Fangyi Wang and Zisheng Qu")
devtools::document()
devtools::document()
devtools::document()
devtools::check()
file.exists("LICENSE")
readLines(".Rbuildignore")
desc <- readLines("DESCRIPTION")
desc[grepl("^License:", desc)]
devtools::document()
devtools::document()
devtools::check()
devtools::document()
devtools::check()
devtools::document()
devtools::document()
devtools::check()
file.exists("LICENSE")
raw <- readBin("DESCRIPTION", "raw", n = 3)
as.character(raw)
read.dcf("DESCRIPTION")
readLines("LICENSE")
packageDescription("data.table")$License
devtools::document()
devtools::document()
devtools::check()
devtools::document()
devtools::check()
devtools::document()
